{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6f9007c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required packages are already installed in this environment.\n"
     ]
    }
   ],
   "source": [
    "# Sezione 1: Assicura anomalib e le librerie necessarie\n",
    "# Evita l'uso diretto di '!pip install anomalib[full]' perch√© zsh espande le parentesi quadre.\n",
    "# Usiamo un approccio sicuro: proviamo a importare i pacchetti e, se mancanti, eseguiamo pip tramite lo stesso interprete Python (sys.executable).\n",
    "import importlib, subprocess, sys\n",
    "required = ['anomalib', 'torch', 'torchvision', 'matplotlib']\n",
    "missing = []\n",
    "for pkg in required:\n",
    "    try:\n",
    "        importlib.import_module(pkg)\n",
    "    except Exception:\n",
    "        missing.append(pkg)\n",
    "if missing:\n",
    "    # If anomalib is missing we attempt to install the 'full' extra.\n",
    "    to_install = []\n",
    "    if 'anomalib' in missing:\n",
    "        # install anomalib with extras using explicit quoting to avoid shell expansion\n",
    "        to_install.append('anomalib[full]')\n",
    "        missing.remove('anomalib')\n",
    "    # add remaining missing packages\n",
    "    to_install.extend(missing)\n",
    "    if to_install:\n",
    "        print('Installing packages:', to_install)\n",
    "        cmd = [sys.executable, '-m', 'pip', 'install'] + to_install\n",
    "        subprocess.check_call(cmd)\n",
    "        print('Installation finished. You might need to restart the kernel to use newly installed packages.')\n",
    "else:\n",
    "    print('All required packages are already installed in this environment.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "997d24e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa le librerie fondamentali\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imposta il seed per la riproducibilit√†\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Imposta tema scuro per matplotlib\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5db14f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kornia_rs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m category = \u001b[33m\"\u001b[39m\u001b[33mscrew\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Puoi cambiare categoria (es. \"bottle\", \"cable\", \"capsule\", ecc.)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01manomalib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MVTecADDataset\n\u001b[32m      4\u001b[39m dataset = MVTecADDataset(\n\u001b[32m      5\u001b[39m     root=Path(\u001b[33m\"\u001b[39m\u001b[33m../.dataset/mvtecad\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      6\u001b[39m     category=category\n\u001b[32m      7\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\coding\\pubblic\\-CV---anomalib-tutorial-with-visualization\\.venv\\Lib\\site-packages\\anomalib\\data\\__init__.py:50\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataclasses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     34\u001b[39m     Batch,\n\u001b[32m     35\u001b[39m     DatasetItem,\n\u001b[32m   (...)\u001b[39m\u001b[32m     46\u001b[39m     VideoItem,\n\u001b[32m     47\u001b[39m )\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Datamodules\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatamodules\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AnomalibDataModule\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatamodules\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdepth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DepthDataFormat, Folder3D, MVTec3D\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatamodules\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     53\u001b[39m     MPDD,\n\u001b[32m     54\u001b[39m     VAD,\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m     Visa,\n\u001b[32m     67\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\coding\\pubblic\\-CV---anomalib-tutorial-with-visualization\\.venv\\Lib\\site-packages\\anomalib\\data\\datamodules\\__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (C) 2025 Intel Corporation\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: Apache-2.0\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"Anomalib Data Modules.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdepth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Folder3D, MVTec3D\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MPDD, VAD, BTech, Datumaro, Folder, Kolektor, MVTec, MVTecAD, Tabular, Visa\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvideo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Avenue, ShanghaiTech, UCSDped\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\coding\\pubblic\\-CV---anomalib-tutorial-with-visualization\\.venv\\Lib\\site-packages\\anomalib\\data\\datamodules\\depth\\__init__.py:8\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"Anomalib Depth Data Modules.\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfolder_3d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Folder3D\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmvtec_3d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MVTec3D\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDepthDataFormat\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m, Enum):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\coding\\pubblic\\-CV---anomalib-tutorial-with-visualization\\.venv\\Lib\\site-packages\\anomalib\\data\\datamodules\\depth\\folder_3d.py:25\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Transform\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01manomalib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatamodules\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AnomalibDataModule\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01manomalib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdepth\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfolder_3d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Folder3DDataset\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01manomalib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Split, TestSplitMode, ValSplitMode\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\coding\\pubblic\\-CV---anomalib-tutorial-with-visualization\\.venv\\Lib\\site-packages\\anomalib\\data\\datamodules\\base\\__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (C) 2022-2025 Intel Corporation\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: Apache-2.0\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"Base Anomalib Data Modules.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AnomalibDataModule\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvideo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AnomalibVideoDataModule\n\u001b[32m      9\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mAnomalibDataModule\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAnomalibVideoDataModule\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\coding\\pubblic\\-CV---anomalib-tutorial-with-visualization\\.venv\\Lib\\site-packages\\anomalib\\data\\datamodules\\base\\image.py:41\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Compose, Resize, Transform\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01manomalib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TaskType\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01manomalib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AnomalibDataset\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01manomalib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m extract_transforms_by_type\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01manomalib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TestSplitMode, ValSplitMode, random_split, split_by_label\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\coding\\pubblic\\-CV---anomalib-tutorial-with-visualization\\.venv\\Lib\\site-packages\\anomalib\\data\\datasets\\__init__.py:42\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (C) 2025 Intel Corporation\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: Apache-2.0\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"PyTorch Dataset implementations for anomaly detection.\u001b[39;00m\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m \u001b[33;03mThis module provides dataset implementations for various anomaly detection tasks:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m \u001b[33;03m    ... )\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AnomalibDataset, AnomalibDepthDataset, AnomalibVideoDataset\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdepth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Folder3DDataset, MVTec3DDataset\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     45\u001b[39m     BTechDataset,\n\u001b[32m     46\u001b[39m     DatumaroDataset,\n\u001b[32m   (...)\u001b[39m\u001b[32m     53\u001b[39m     VisaDataset,\n\u001b[32m     54\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\coding\\pubblic\\-CV---anomalib-tutorial-with-visualization\\.venv\\Lib\\site-packages\\anomalib\\data\\datasets\\base\\__init__.py:17\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (C) 2024 Intel Corporation\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: Apache-2.0\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"Base Classes for Torch Datasets.\u001b[39;00m\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m \u001b[33;03mThis module contains the base dataset classes used in anomalib for different data\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \u001b[33;03mto anomaly detection tasks.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdepth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AnomalibDepthDataset\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AnomalibDataset\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvideo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AnomalibVideoDataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\coding\\pubblic\\-CV---anomalib-tutorial-with-visualization\\.venv\\Lib\\site-packages\\anomalib\\data\\datasets\\base\\depth.py:21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01manomalib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TaskType\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01manomalib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataclasses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DepthBatch, DepthItem\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01manomalib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelName, read_depth_image\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AnomalibDataset\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mAnomalibDepthDataset\u001b[39;00m(AnomalibDataset, ABC):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\coding\\pubblic\\-CV---anomalib-tutorial-with-visualization\\.venv\\Lib\\site-packages\\anomalib\\data\\utils\\__init__.py:25\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (C) 2022-2025 Intel Corporation\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: Apache-2.0\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"Helper utilities for data.\u001b[39;00m\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m \u001b[33;03mThis module provides various utility functions for data handling in Anomalib.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m \u001b[33;03m    >>> noise = generate_perlin_noise(256, 256)\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mboxes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m boxes_to_anomaly_maps, boxes_to_masks, masks_to_boxes\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdownload\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DownloadInfo, download_and_extract\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenerators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m generate_perlin_noise\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\coding\\pubblic\\-CV---anomalib-tutorial-with-visualization\\.venv\\Lib\\site-packages\\anomalib\\data\\utils\\boxes.py:12\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"Helper functions for processing bounding box detections and annotations.\u001b[39;00m\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m \u001b[33;03mThis module provides utility functions for converting between different bounding box\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03mformats and handling bounding box operations.\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01manomalib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m connected_components_cpu, connected_components_gpu\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmasks_to_boxes\u001b[39m(\n\u001b[32m     16\u001b[39m     masks: torch.Tensor,\n\u001b[32m     17\u001b[39m     anomaly_maps: torch.Tensor | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     18\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mlist\u001b[39m[torch.Tensor], \u001b[38;5;28mlist\u001b[39m[torch.Tensor]]:\n\u001b[32m     19\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Convert batch of segmentation masks to bounding box coordinates.\u001b[39;00m\n\u001b[32m     20\u001b[39m \n\u001b[32m     21\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m \u001b[33;03m        tensor([[15., 10., 24., 19.]])\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\coding\\pubblic\\-CV---anomalib-tutorial-with-visualization\\.venv\\Lib\\site-packages\\anomalib\\utils\\cv\\__init__.py:22\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (C) 2022-2025 Intel Corporation\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: Apache-2.0\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"Computer vision utilities for anomaly detection.\u001b[39;00m\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m \u001b[33;03mThis module provides computer vision utilities used by the anomalib library for\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m \u001b[33;03m    >>> labels = connected_components_cpu(mask)\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnected_components\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m connected_components_cpu, connected_components_gpu\n\u001b[32m     24\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mconnected_components_cpu\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mconnected_components_gpu\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\coding\\pubblic\\-CV---anomalib-tutorial-with-visualization\\.venv\\Lib\\site-packages\\anomalib\\utils\\cv\\connected_components.py:25\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkornia\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontrib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m connected_components\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnected_components_gpu\u001b[39m(image: torch.Tensor, num_iterations: \u001b[38;5;28mint\u001b[39m = \u001b[32m1000\u001b[39m) -> torch.Tensor:\n\u001b[32m     29\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Perform connected component labeling on GPU.\u001b[39;00m\n\u001b[32m     30\u001b[39m \n\u001b[32m     31\u001b[39m \u001b[33;03m    Labels connected regions in a binary image and remaps the labels sequentially\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m \u001b[33;03m                [0, 0, 0, 0]])\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\coding\\pubblic\\-CV---anomalib-tutorial-with-visualization\\.venv\\Lib\\site-packages\\kornia\\__init__.py:20\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# LICENSE HEADER MANAGED BY add-license-header\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Copyright 2018 Kornia Team\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# NOTE: kornia filters and geometry must go first since are the core of the library\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# and by changing the import order you might get into a circular dependencies issue.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m filters\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m geometry\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m grad_estimator\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\coding\\pubblic\\-CV---anomalib-tutorial-with-visualization\\.venv\\Lib\\site-packages\\kornia\\filters\\__init__.py:20\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# LICENSE HEADER MANAGED BY add-license-header\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Copyright 2018 Kornia Team\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbilateral\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BilateralBlur, JointBilateralBlur, bilateral_blur, joint_bilateral_blur\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mblur\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BoxBlur, box_blur\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mblur_pool\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     23\u001b[39m     BlurPool2D,\n\u001b[32m     24\u001b[39m     EdgeAwareBlurPool2D,\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m     max_blur_pool2d,\n\u001b[32m     29\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\coding\\pubblic\\-CV---anomalib-tutorial-with-visualization\\.venv\\Lib\\site-packages\\kornia\\filters\\bilateral.py:26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkornia\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor, pad\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkornia\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheck\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KORNIA_CHECK, KORNIA_CHECK_IS_TENSOR, KORNIA_CHECK_SHAPE\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkernels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _unpack_2d_ks, get_gaussian_kernel2d\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmedian\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _compute_zero_padding\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_bilateral_blur\u001b[39m(\n\u001b[32m     31\u001b[39m     \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[32m     32\u001b[39m     guidance: Optional[Tensor],\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m     color_distance_type: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33ml1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m ) -> Tensor:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\coding\\pubblic\\-CV---anomalib-tutorial-with-visualization\\.venv\\Lib\\site-packages\\kornia\\filters\\kernels.py:28\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkornia\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Device, Dtype, Tensor, concatenate, cos, stack, tensor, where, zeros, zeros_like\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkornia\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheck\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KORNIA_CHECK, KORNIA_CHECK_IS_TENSOR, KORNIA_CHECK_SHAPE\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkornia\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_kernel_size\u001b[39m(kernel_size: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, ...] | \u001b[38;5;28mint\u001b[39m, min_value: \u001b[38;5;28mint\u001b[39m = \u001b[32m0\u001b[39m, allow_even: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(kernel_size, \u001b[38;5;28mint\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\coding\\pubblic\\-CV---anomalib-tutorial-with-visualization\\.venv\\Lib\\site-packages\\kornia\\utils\\__init__.py:38\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhelpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     23\u001b[39m     _extract_device_dtype,\n\u001b[32m     24\u001b[39m     dataclass_to_dict,\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     xla_is_available,\n\u001b[32m     36\u001b[39m )\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageToTensor, image_list_to_tensor, image_to_tensor, tensor_to_image\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_print\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m image_to_string, print_image\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmemory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m batched_forward\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     41\u001b[39m     differentiable_clipping,\n\u001b[32m     42\u001b[39m     differentiable_polynomial_floor,\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     vec_like,\n\u001b[32m     46\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\coding\\pubblic\\-CV---anomalib-tutorial-with-visualization\\.venv\\Lib\\site-packages\\kornia\\utils\\image_print.py:33\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkornia\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkornia\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheck\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KORNIA_CHECK_IS_IMAGE, KORNIA_CHECK_SHAPE\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkornia\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageLoadType\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# color look-up table\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# 8-bit, RGB hex\u001b[39;00m\n\u001b[32m     37\u001b[39m CLUT = [\n\u001b[32m     38\u001b[39m     \u001b[38;5;66;03m# Primary 3-bit (8 colors). Unique representation!\u001b[39;00m\n\u001b[32m     39\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33m00\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m000000\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m    297\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33m255\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33meeeeee\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    298\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\coding\\pubblic\\-CV---anomalib-tutorial-with-visualization\\.venv\\Lib\\site-packages\\kornia\\io\\__init__.py:18\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# LICENSE HEADER MANAGED BY add-license-header\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Copyright 2018 Kornia Team\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageLoadType, load_image, write_image\n\u001b[32m     20\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mImageLoadType\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mload_image\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwrite_image\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\coding\\pubblic\\-CV---anomalib-tutorial-with-visualization\\.venv\\Lib\\site-packages\\kornia\\io\\io.py:24\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkornia_rs\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkornia\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\coding\\pubblic\\-CV---anomalib-tutorial-with-visualization\\.venv\\Lib\\site-packages\\kornia_rs\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkornia_rs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[34m__doc__\u001b[39m = \u001b[43mkornia_rs\u001b[49m.\u001b[34m__doc__\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(kornia_rs, \u001b[33m\"\u001b[39m\u001b[33m__all__\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      5\u001b[39m     __all__ = kornia_rs.__all__\n",
      "\u001b[31mNameError\u001b[39m: name 'kornia_rs' is not defined"
     ]
    }
   ],
   "source": [
    "category = \"screw\"  # Puoi cambiare categoria (es. \"bottle\", \"cable\", \"capsule\", ecc.)\n",
    "from pathlib import Path\n",
    "from anomalib.data.datasets import MVTecADDataset\n",
    "dataset = MVTecADDataset(\n",
    "    root=Path(\"../.dataset/mvtecad\"),\n",
    "    category=category\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4f794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8224ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.samples.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434ca58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path = df.iloc[17,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f44e558",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_img_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Carica e mostra l'immagine dal path test_img_path\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m img = Image.open(\u001b[43mtest_img_path\u001b[49m)\n\u001b[32m      6\u001b[39m plt.imshow(np.asarray(img))\n\u001b[32m      7\u001b[39m plt.title(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mContenuto di \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_img_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'test_img_path' is not defined"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Carica e mostra l'immagine dal path test_img_path\n",
    "img = Image.open(test_img_path)\n",
    "plt.imshow(np.asarray(img))\n",
    "plt.title(f'Contenuto di {test_img_path}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c68c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.asarray(img)[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1430ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controlli diagnostici dettagliati per GPU/CUDA\n",
    "import torch\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"=== DIAGNOSI GPU/CUDA ===\")\n",
    "print(f\"Versione Python: {sys.version}\")\n",
    "print(f\"Versione PyTorch: {torch.__version__}\")\n",
    "\n",
    "# 1. Verifica CUDA disponibilit√†\n",
    "print(f\"\\ntorch.cuda.is_available(): {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"  Memory: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"CUDA non disponibile\")\n",
    "\n",
    "# 2. Verifica versione CUDA compilata in PyTorch\n",
    "print(f\"\\nCUDA version compilata in PyTorch: {torch.version.cuda}\")\n",
    "\n",
    "# 3. Verifica se PyTorch √® stato compilato con supporto CUDA\n",
    "print(f\"PyTorch compilato con CUDA: {torch.cuda.is_available()}\")\n",
    "\n",
    "# 4. Verifica driver NVIDIA (se su Windows)\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, shell=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"\\nnvidia-smi output:\")\n",
    "        print(result.stdout)\n",
    "    else:\n",
    "        print(f\"\\nnvidia-smi non trovato o errore: {result.stderr}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nErrore nell'eseguire nvidia-smi: {e}\")\n",
    "\n",
    "# 5. Verifica variabili d'ambiente CUDA\n",
    "import os\n",
    "cuda_path = os.environ.get('CUDA_PATH', 'Non trovato')\n",
    "cuda_home = os.environ.get('CUDA_HOME', 'Non trovato')\n",
    "print(f\"\\nCUDA_PATH: {cuda_path}\")\n",
    "print(f\"CUDA_HOME: {cuda_home}\")\n",
    "\n",
    "print(\"\\n=== FINE DIAGNOSI ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdd69da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOMATIZZAZIONE: Reinstallazione PyTorch con supporto CUDA\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def reinstall_pytorch_cuda():\n",
    "    \"\"\"Reinstalla PyTorch con supporto CUDA\"\"\"\n",
    "    try:\n",
    "        print(\"üîÑ Disinstallazione PyTorch CPU-only...\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'uninstall', 'torch', 'torchvision', 'torchaudio', '-y'])\n",
    "        \n",
    "        print(\"üì¶ Installazione PyTorch con supporto CUDA 12.1...\")\n",
    "        subprocess.check_call([\n",
    "            sys.executable, '-m', 'pip', 'install', \n",
    "            'torch', 'torchvision', 'torchaudio',\n",
    "            '--index-url', 'https://download.pytorch.org/whl/cu121'\n",
    "        ])\n",
    "        \n",
    "        print(\"‚úÖ Installazione completata!\")\n",
    "        print(\"‚ö†Ô∏è  IMPORTANTE: Riavvia il kernel del notebook per applicare le modifiche!\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Errore durante l'installazione: {e}\")\n",
    "        return False\n",
    "\n",
    "# Decommentare la riga sotto per eseguire la reinstallazione\n",
    "# reinstall_pytorch_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6f6491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ VERIFICA FINALE: GPU ora dovrebbe funzionare!\n",
    "# IMPORTANTE: Prima di eseguire questa cella, riavvia il kernel del notebook!\n",
    "\n",
    "import torch\n",
    "print(\"üîç VERIFICA FINALE DOPO REINSTALLAZIONE:\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ SUCCESS! GPU rilevata: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    \n",
    "    # Test rapido di allocazione GPU\n",
    "    device = torch.device(\"cuda\")\n",
    "    test_tensor = torch.randn(1000, 1000).to(device)\n",
    "    print(f\"‚úÖ Test allocazione GPU: OK ({test_tensor.device})\")\n",
    "    del test_tensor\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"‚ùå CUDA ancora non disponibile. Assicurati di aver riavviato il kernel!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0088d29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Determina il device corretto per Mac (MPS), CUDA (Windows/Linux), o CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using device: {device} ({torch.cuda.get_device_name(0)})\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f\"Using device: {device} (Apple Silicon MPS)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using device: cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb9116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisci MVTecDataset all'inizio del modulo principale\n",
    "class MVTecDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, category, train=True, transform=None):\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        path = os.path.join(\".dataset/mvtecad\", category, \"train\" if train else \"test\")\n",
    "        self.good_path = os.path.join(path, \"good\")\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.subfolders = []\n",
    "\n",
    "        if train:\n",
    "            # Solo immagini good per il training\n",
    "            self.image_paths = [os.path.join(self.good_path, f) for f in os.listdir(self.good_path) \n",
    "                                if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        else:\n",
    "            # Per il test: crea sottocartelle per ogni tipo (comprese good)\n",
    "            for defect_type in os.listdir(path):\n",
    "                defect_path = os.path.join(path, defect_type)\n",
    "                if os.path.isdir(defect_path):\n",
    "                    files = [f for f in os.listdir(defect_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "                    for f in files:\n",
    "                        self.image_paths.append(os.path.join(defect_path, f))\n",
    "                        self.labels.append(defect_type)\n",
    "                        self.subfolders.append(defect_type)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.train:\n",
    "            return img\n",
    "        else:\n",
    "            # Restituisci anche la sottocartella (defect_type) e il nome file\n",
    "            file_name = os.path.basename(self.image_paths[idx])\n",
    "            defect_type = self.subfolders[idx]\n",
    "            return img, defect_type, file_name\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Modello convoluzionale\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 25, kernel_size=5 , padding=2 , padding_mode='replicate')  # Mantieni dimensioni\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(25, 50, kernel_size=3, padding=1, padding_mode='replicate') \n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(50, 75, kernel_size=3, padding=1, padding_mode='replicate')\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.conv4 = nn.Conv2d(75, 100, kernel_size=3, padding=1, padding_mode='replicate')\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.conv1(x))  # 25x256x256\n",
    "        x = self.relu2(self.conv2(x))  # 50x256x256\n",
    "        x = self.relu3(self.conv3(x))  # 75x256x256\n",
    "        x = self.relu4(self.conv4(x))  # 100x256x256\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ca7039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzioni di supporto\n",
    "def extract_compact_patches(\n",
    "    features: torch.Tensor, \n",
    "    patch_size=3, \n",
    "    reduction='mean', \n",
    "    stride=1, \n",
    "    padding=0\n",
    "    ) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Estrae patch da una feature map 4D usando sliding window (simile a una convoluzione), con supporto per stride e padding.\n",
    "\n",
    "    Args:\n",
    "        features: torch.Tensor di shape (batch, channels, height, width)\n",
    "        patch_size: dimensione della patch quadrata (es: 5 -> 5x5)\n",
    "        reduction: Metodo di riduzione ('mean' per media, 'max' per massimo, o altro)\n",
    "        stride: Passo della finestra (default=1)\n",
    "        padding: Padding da applicare ai bordi (default=0)\n",
    "\n",
    "    Returns:\n",
    "        patches_reduced: torch.Tensor di shape (num_patches_totali, channels)\n",
    "\n",
    "    Notes:\n",
    "        - Ogni patch viene ridotta a un vettore 1D per canale (utile per clustering o altre analisi).\n",
    "        - La funzione restituisce un array 2D (num_patches_totali, channels).\n",
    "\n",
    "    Examples:\n",
    "        # Esempio con immagine 4x4 a 3 canali\n",
    "        img = torch.arange(4*4*3).reshape(1,3,4,4).float()\n",
    "        print(\"Input shape:\", img.shape)\n",
    "        print(\"Input[0,0]:\\n\", img[0,0])\n",
    "        patches = extract_compact_patches(img, patch_size=2, stride=2)\n",
    "        print(\"Patches shape:\", patches.shape)  # (4, 3)\n",
    "        print(\"Patches:\\n\", patches)\n",
    "        # Ogni riga di patches √® la media dei valori di una patch 2x2 per ogni canale\n",
    "\n",
    "        # Esempio con feature map (2, 3, 16, 16)\n",
    "        features = torch.randn(2, 3, 16, 16)\n",
    "        patches = extract_compact_patches(features, patch_size=5, stride=2)\n",
    "        print(patches.shape)  # (num_patches_totali, 3)\n",
    "        print(patches[0])     # Vettore 1D di lunghezza 3 (media di ogni canale)\n",
    "        print(patches[:5])    # Prime 5 patch\n",
    "        print(patches.mean(dim=0))  # Media globale per canale\n",
    "    \"\"\"\n",
    "    # Applica padding se richiesto\n",
    "    if padding > 0:\n",
    "        features = torch.nn.functional.pad(features, (padding, padding, padding, padding))\n",
    "\n",
    "    batch_size, channels, height, width = features.shape\n",
    "\n",
    "    # Estrai patch con unfold su height e width\n",
    "    patches = features.unfold(2, patch_size, stride).unfold(3, patch_size, stride)\n",
    "    # patches shape: (batch, channels, num_patches_h, num_patches_w, patch_size, patch_size)\n",
    "\n",
    "    # Porta tutte le patch in una sola dimensione\n",
    "    patches = patches.contiguous().view(batch_size, channels, -1, patch_size, patch_size)  # (batch, channels, num_patches, patch_size, patch_size)\n",
    "\n",
    "    # Calcola la media su ogni patch per ogni canale\n",
    "    # Risultato: (batch, channels, num_patches)\n",
    "    patches_reduced = patches.mean(dim=[3, 4])\n",
    "\n",
    "    # Porta la dimensione dei canali in fondo: (batch, num_patches, channels)\n",
    "    patches_reduced = patches_reduced.permute(0, 2, 1)\n",
    "\n",
    "    # Unisci tutti i batch in una sola dimensione: (num_patches_totali, channels)\n",
    "    patches_reduced = patches_reduced.reshape(-1, channels)\n",
    "\n",
    "    return patches_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1b01e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Carica l'immagine\n",
    "good_image_path = \"002.png\"\n",
    "good_img = Image.open(good_image_path).resize((256, 256))\n",
    "# Plotta l'immagine\n",
    "plt.imshow(good_img)\n",
    "print(f\"Dimensioni immagine: {np.asarray(good_img).shape}\")\n",
    "plt.title(\"aaa.jpg\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3166021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert the PIL.Image object to a NumPy array\n",
    "good_img_np = np.asarray(good_img)\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(12, 3))\n",
    "for i in range(3):\n",
    "    axs[i].imshow(good_img_np[..., i], cmap='gray')\n",
    "    axs[i].set_title(f'Canale {i+1}')\n",
    "    axs[i].axis('off')\n",
    "axs[3].imshow(good_img_np)\n",
    "axs[3].set_title('RGB')\n",
    "axs[3].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.title(f\"Immagine GOOD {good_img_np.shape}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f3d985",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 10\n",
    "stride = 1\n",
    "padding = 0\n",
    "reduction = 'mean'\n",
    "\n",
    "# Inizializza il modello di feature extraction\n",
    "model = FeatureExtractor()\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Prepara l'immagine come batch torch.Tensor (1, C, H, W)\n",
    "img_tensor = torch.from_numpy(good_img_np.astype(np.float32)).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    features = model(img_tensor)\n",
    "    patches = extract_compact_patches(features, patch_size=patch_size, stride=stride, padding=padding, reduction=reduction)\n",
    "    all_good_patches = patches.cpu()\n",
    "\n",
    "patch_height = np.sqrt(all_good_patches.shape[0]).astype(int)\n",
    "patch_width = patch_height\n",
    "\n",
    "print(f\"Total patches extracted: {len(all_good_patches)}\")\n",
    "print(f\"Each patch is a vector of length: {all_good_patches.shape[1]} (number of channels)\")\n",
    "print(f\"Each feature image has a shape of: {patch_height} * {patch_width} (height x width)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e28d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pic =26  # Indice dell'immagine da visualizzare\n",
    "pic = []\n",
    "for channel in all_good_patches:\n",
    "    pic.append(channel[id_pic])\n",
    "pic = np.array(pic).reshape(patch_height, patch_width)  \n",
    "plt.axis('off')\n",
    "plt.imshow(pic, cmap='plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08908cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images_from_patches_boosted(all_patches, patch_height, patch_width):\n",
    "    \"\"\"\n",
    "    Genera immagini dai patch e le ridimensiona utilizzando PyTorch per ottimizzare le operazioni.\n",
    "\n",
    "    Args:\n",
    "        all_patches (torch.Tensor): Tensor contenente tutti i patch di dimensione (num_patches, channels).\n",
    "        patch_height (int): Altezza di ciascun patch.\n",
    "        patch_width (int): Larghezza di ciascun patch.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Tensor contenente le immagini ridimensionate di dimensione (num_images, patch_height, patch_width).\n",
    "    \"\"\"\n",
    "    # Reshape diretto usando PyTorch per evitare loop\n",
    "    num_patches, channels = all_patches.shape\n",
    "    num_images = channels\n",
    "    reshaped_images = all_patches.T.reshape(num_images, patch_height, patch_width)\n",
    "    return reshaped_images\n",
    "\n",
    "# Generate images\n",
    "fig, axs = plt.subplots(10, 10, figsize=(10, 7))\n",
    "axs = axs.flatten()\n",
    "images = generate_images_from_patches_boosted(all_good_patches, patch_height, patch_width)\n",
    "\n",
    "# Display the patches\n",
    "for i, img in enumerate(images):\n",
    "    im = axs[i].imshow(img, cmap='plasma')\n",
    "    axs[i].axis('off')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896cb995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assumendo che all_patches sia un torch.Tensor, lo convertiamo in numpy\n",
    "patches_np = all_good_patches.cpu().numpy()\n",
    "\n",
    "# Numero di righe e colonne nella griglia\n",
    "num_rows = 10\n",
    "num_cols = 5\n",
    "offset = len(all_good_patches)//2 + 240 # Offset per selezionare patch diverse\n",
    "\n",
    "# Seleziona le prime (num_rows * num_cols) patch\n",
    "selected_patches = patches_np[offset : num_cols * num_rows + offset]\n",
    "\n",
    "# Calcola il minimo e il massimo per ogni colonna (indice)\n",
    "col_min = selected_patches.min(axis=0)\n",
    "col_max = selected_patches.max(axis=0)\n",
    "\n",
    "# Evita la divisione per zero\n",
    "range_col = col_max - col_min\n",
    "range_col[range_col == 0] = 1  # Se il range √® 0, impostalo a 1 per evitare errori\n",
    "\n",
    "# Normalizza ogni elemento relativamente alla colonna\n",
    "normalized_patches = (selected_patches - col_min) / range_col\n",
    "\n",
    "# Crea la figura e gli assi\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 5))\n",
    "\n",
    "\n",
    "# Itera sulle patch selezionate e sugli assi\n",
    "for i, patch in enumerate(normalized_patches):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    \n",
    "    # Reshape della patch in una matrice 1x100\n",
    "    patch_reshaped = patch.reshape(1, -1)\n",
    "    \n",
    "    # Mostra la heatmap\n",
    "    axs[row, col].imshow(patch_reshaped, cmap='plasma', aspect='auto')\n",
    "    axs[row, col].axis('off')  # Nascondi gli assi\n",
    "\n",
    "# Migliora il layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4027f01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image_90(image):\n",
    "    \"\"\"\n",
    "    Ruota un'immagine di 90 gradi in senso orario.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray o torch.Tensor): L'immagine da ruotare.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray o torch.Tensor: L'immagine ruotata.\n",
    "    \"\"\"\n",
    "    if isinstance(image, np.ndarray):\n",
    "        return np.rot90(image, k=-1)  # Ruota di 90 gradi in senso orario\n",
    "    elif isinstance(image, torch.Tensor):\n",
    "        return torch.rot90(image, k=-1, dims=(1, 2))  # Ruota di 90 gradi in senso orario\n",
    "    else:\n",
    "        raise TypeError(\"Il formato dell'immagine deve essere numpy.ndarray o torch.Tensor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5292c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica l'immagine\n",
    "test_image_path = \"008.png\"\n",
    "test_img = Image.open(test_image_path).resize((256, 256))\n",
    "test_img = rotate_image_90(np.array(test_img))\n",
    "# Plotta l'immagine\n",
    "plt.axis('off')\n",
    "plt.imshow(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad6f046",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Mostra good_img\n",
    "axs[0].imshow(good_img)\n",
    "axs[0].set_title(\"Original Basketball Image\")\n",
    "axs[0].axis('off')\n",
    "\n",
    "# Mostra test_img\n",
    "axs[1].imshow(test_img)\n",
    "axs[1].set_title(\"Rotated Noisy Image\")\n",
    "axs[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd87b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_np = np.asarray(test_img)\n",
    "\n",
    "# Prepara l'immagine come batch torch.Tensor (1, C, H, W)\n",
    "test_tensor = torch.from_numpy(test_img_np.astype(np.float32)).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_features = model(test_tensor)\n",
    "    test_patches = extract_compact_patches(test_features, patch_size=patch_size, stride=stride, padding=padding, reduction=reduction)\n",
    "    all_test_patches = test_patches.cpu()\n",
    "\n",
    "patch_height = np.sqrt(all_test_patches.shape[0]).astype(int)\n",
    "patch_width = patch_height\n",
    "\n",
    "print(f\"Total patches extracted: {len(all_test_patches)}\")\n",
    "print(f\"Each patch is a vector of length: {all_test_patches.shape[1]} (number of channels)\")\n",
    "print(f\"Each feature image has a shape of: {patch_height} * {patch_width} (height x width)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6874a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install faiss if not already installed\n",
    "%pip install faiss-gpu\n",
    "\n",
    "# Importa faiss-gpu e carica tutti i vettori contenuti in all_good_patches\n",
    "import faiss\n",
    "import torch\n",
    "\n",
    "# Assicurati che all_good_patches sia un torch.Tensor su CPU\n",
    "if isinstance(all_good_patches, torch.Tensor):\n",
    "    vectors = all_good_patches.cpu().numpy().astype('float32')\n",
    "else:\n",
    "    vectors = np.array(all_good_patches, dtype='float32')\n",
    "\n",
    "print(f\"Shape dei vettori caricati in FAISS: {vectors.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2710026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "# Crea un indice L2 flat solo CPU\n",
    "index = faiss.IndexFlatL2(vectors.shape[1])\n",
    "\n",
    "# Aggiungi i vettori all'indice CPU\n",
    "index.add(vectors)\n",
    "\n",
    "print(f\"Indice FAISS creato su CPU. Numero di vettori indicizzati: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cb436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona una patch da all_test_patches (ad esempio la prima)\n",
    "query_patch = all_test_patches[30001].numpy().astype('float32').reshape(1, -1)  # shape (1, dim)\n",
    "\n",
    "# Esegui la ricerca dei 3 vicini pi√π prossimi nell'indice FAISS creato su all_patches\n",
    "D, I = index.search(query_patch, 3)  # D: distanze, I: indici\n",
    "\n",
    "print(\"Indici dei 3 vettori pi√π vicini:\", I[0])\n",
    "print(\"Distanze corrispondenti:\", D[0])\n",
    "\n",
    "# Visualizza i vettori trovati\n",
    "for idx, (i, d) in enumerate(zip(I[0], D[0])):\n",
    "    print(f\"\\nVicino #{idx+1} (indice {i}, distanza {d:.4f}):\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e65a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Converte all_test_patches in numpy array se necessario\n",
    "if isinstance(all_test_patches, torch.Tensor):\n",
    "    test_vectors = all_test_patches.cpu().numpy().astype('float32')\n",
    "else:\n",
    "    test_vectors = np.array(all_test_patches, dtype='float32')\n",
    "\n",
    "# Per ogni patch, cerca il vicino pi√π vicino (k=1)\n",
    "D, I = index.search(test_vectors, 1)  # D: distanze, I: indici\n",
    "\n",
    "# D ha shape (num_patches, 1): estrai solo la colonna delle distanze\n",
    "min_distances = D[:, 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17387772",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339cc82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Ricostruisci la mappa 2D delle distanze minime (assumendo patch_height e patch_width gi√† definiti)\n",
    "min_distances_2d = min_distances.reshape(patch_height, patch_width)\n",
    "\n",
    "# Ruota la mappa delle distanze minime di 90 gradi\n",
    "rotated_min_distances_2d = rotate_image_90(min_distances_2d)\n",
    "\n",
    "# Ridimensiona le immagini ai lati alla stessa dimensione della heatmap\n",
    "target_size = (min_distances_2d.shape[1], min_distances_2d.shape[0])\n",
    "resized_good_img = good_img.resize(target_size)\n",
    "resized_test_img = test_img.resize(target_size)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Immagine originale\n",
    "axs[0].imshow(resized_good_img)\n",
    "axs[0].set_title(\"Immagine Originale\")\n",
    "axs[0].axis('off')\n",
    "\n",
    "# Heatmap (stessa size delle immagini)\n",
    "im = axs[1].imshow(min_distances_2d, cmap='magma', aspect='auto')\n",
    "axs[1].set_title('Heatmap delle distanze minime (anomaly map)')\n",
    "axs[1].axis('off')\n",
    "# fig.colorbar(im, ax=axs[1], shrink=0.8, label='Distanza dal vicino pi√π vicino')\n",
    "\n",
    "# Immagine anomala\n",
    "axs[2].imshow(resized_test_img)\n",
    "axs[2].set_title(\"Immagine Anomala\")\n",
    "axs[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4c754f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
